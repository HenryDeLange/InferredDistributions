package mywild.inferreddistributions;

import java.awt.Cursor;
import java.awt.EventQueue;
import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.IOException;
import java.nio.file.FileVisitResult;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.SimpleFileVisitor;
import java.nio.file.attribute.BasicFileAttributes;
import java.util.ArrayList;
import java.util.List;
import java.util.logging.Level;
import java.util.logging.Logger;
import javax.swing.JFileChooser;
import javax.swing.JFrame;
import javax.swing.JOptionPane;
import javax.swing.UIManager;
import javax.swing.UnsupportedLookAndFeelException;
import org.neuroph.core.NeuralNetwork;
import org.neuroph.core.data.DataSet;
import org.neuroph.core.data.DataSetRow;
import org.neuroph.nnet.MultiLayerPerceptron;
import org.neuroph.nnet.learning.BackPropagation;

public class NeuralNetworkProcessorApp extends JFrame {
    private String distributionsFolder = Paths.get(System.getProperty("user.home"), 
            "InferredDistributions", "NeuralNetwork", "Distributions").toAbsolutePath().toString();
    private String trainingInputsFolder = Paths.get(System.getProperty("user.home"), 
            "InferredDistributions", "NeuralNetwork", "TrainingInputs").toAbsolutePath().toString();

    public NeuralNetworkProcessorApp() {
        initComponents();
    }
    
    public static void main(String args[]) {
        // Set native Look and Feel
        try {
            UIManager.setLookAndFeel(UIManager.getSystemLookAndFeelClassName());
        }
        catch (ClassNotFoundException | InstantiationException | IllegalAccessException | UnsupportedLookAndFeelException ex) {
            Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.SEVERE, null, ex);
        }
        // Launch the application
        EventQueue.invokeLater(new Runnable() {
            public void run() {
                NeuralNetworkProcessorApp app = new NeuralNetworkProcessorApp();
                app.setLocationRelativeTo(null);
                app.setVisible(true);
            }
        });
    }

    /**
     * This method is called from within the constructor to initialize the form. WARNING: Do NOT modify this code. The content of this method is always regenerated by the Form Editor.
     */
    @SuppressWarnings("unchecked")
    // <editor-fold defaultstate="collapsed" desc="Generated Code">//GEN-BEGIN:initComponents
    private void initComponents() {

        jLabel1 = new javax.swing.JLabel();
        jPanel2 = new javax.swing.JPanel();
        jLabel7 = new javax.swing.JLabel();
        txtDistributionsFolderPath = new javax.swing.JTextField();
        btnDistributionsBrowse = new javax.swing.JButton();
        jPanel4 = new javax.swing.JPanel();
        jLabel9 = new javax.swing.JLabel();
        chkReplaceFiles = new javax.swing.JCheckBox();
        jLabel13 = new javax.swing.JLabel();
        chkIncludeAbsence = new javax.swing.JCheckBox();
        jLabel11 = new javax.swing.JLabel();
        txtLayersAndNodes = new javax.swing.JTextField();
        jLabel12 = new javax.swing.JLabel();
        btnGenerateDatasets = new javax.swing.JButton();
        btnTrainNeuralNetwork = new javax.swing.JButton();
        btnGenerateDistribution = new javax.swing.JButton();
        jPanel8 = new javax.swing.JPanel();
        jLabel19 = new javax.swing.JLabel();
        txtTrainingInputsFolderPath = new javax.swing.JTextField();
        btnTrainingInputsBrowse = new javax.swing.JButton();

        setDefaultCloseOperation(javax.swing.WindowConstants.EXIT_ON_CLOSE);
        setTitle("Neural Network Processor");

        jLabel1.setFont(jLabel1.getFont().deriveFont(jLabel1.getFont().getStyle() | java.awt.Font.BOLD, jLabel1.getFont().getSize()+15));
        jLabel1.setText("Neural Network Processor");

        jLabel7.setFont(jLabel7.getFont().deriveFont(jLabel7.getFont().getStyle() | java.awt.Font.BOLD, jLabel7.getFont().getSize()+6));
        jLabel7.setText("Distribution Datasets Folder");

        txtDistributionsFolderPath.setFont(txtDistributionsFolderPath.getFont().deriveFont(txtDistributionsFolderPath.getFont().getSize()+2f));
        txtDistributionsFolderPath.setHorizontalAlignment(javax.swing.JTextField.CENTER);
        txtDistributionsFolderPath.setText(distributionsFolder);
        txtDistributionsFolderPath.setEnabled(false);
        txtDistributionsFolderPath.setMinimumSize(new java.awt.Dimension(300, 22));
        txtDistributionsFolderPath.setPreferredSize(new java.awt.Dimension(400, 22));

        btnDistributionsBrowse.setFont(btnDistributionsBrowse.getFont().deriveFont(btnDistributionsBrowse.getFont().getSize()+2f));
        btnDistributionsBrowse.setText("Browse");
        btnDistributionsBrowse.setCursor(new java.awt.Cursor(java.awt.Cursor.HAND_CURSOR));
        btnDistributionsBrowse.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                btnDistributionsBrowseActionPerformed(evt);
            }
        });

        javax.swing.GroupLayout jPanel2Layout = new javax.swing.GroupLayout(jPanel2);
        jPanel2.setLayout(jPanel2Layout);
        jPanel2Layout.setHorizontalGroup(
            jPanel2Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(jPanel2Layout.createSequentialGroup()
                .addGap(5, 5, 5)
                .addGroup(jPanel2Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                    .addGroup(jPanel2Layout.createSequentialGroup()
                        .addComponent(jLabel7)
                        .addGap(0, 0, Short.MAX_VALUE))
                    .addGroup(jPanel2Layout.createSequentialGroup()
                        .addComponent(txtDistributionsFolderPath, javax.swing.GroupLayout.DEFAULT_SIZE, 738, Short.MAX_VALUE)
                        .addGap(5, 5, 5)
                        .addComponent(btnDistributionsBrowse, javax.swing.GroupLayout.PREFERRED_SIZE, 107, javax.swing.GroupLayout.PREFERRED_SIZE)))
                .addGap(5, 5, 5))
        );
        jPanel2Layout.setVerticalGroup(
            jPanel2Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(jPanel2Layout.createSequentialGroup()
                .addGap(5, 5, 5)
                .addComponent(jLabel7)
                .addGap(5, 5, 5)
                .addGroup(jPanel2Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.BASELINE)
                    .addComponent(txtDistributionsFolderPath, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                    .addComponent(btnDistributionsBrowse))
                .addGap(5, 5, 5))
        );

        jLabel9.setFont(jLabel9.getFont().deriveFont(jLabel9.getFont().getStyle() | java.awt.Font.BOLD, jLabel9.getFont().getSize()+6));
        jLabel9.setText("Options");

        chkReplaceFiles.setFont(chkReplaceFiles.getFont().deriveFont(chkReplaceFiles.getFont().getSize()+1f));
        chkReplaceFiles.setSelected(true);
        chkReplaceFiles.setText("Replace exisitng files");
        chkReplaceFiles.setCursor(new java.awt.Cursor(java.awt.Cursor.HAND_CURSOR));

        jLabel13.setFont(jLabel13.getFont().deriveFont(jLabel13.getFont().getStyle() | java.awt.Font.BOLD, jLabel13.getFont().getSize()+1));
        jLabel13.setText("Settings:");

        chkIncludeAbsence.setFont(chkIncludeAbsence.getFont().deriveFont(chkIncludeAbsence.getFont().getSize()+1f));
        chkIncludeAbsence.setSelected(true);
        chkIncludeAbsence.setText("Include absence records for the training and testing datasets");
        chkIncludeAbsence.setCursor(new java.awt.Cursor(java.awt.Cursor.HAND_CURSOR));

        jLabel11.setFont(jLabel11.getFont().deriveFont(jLabel11.getFont().getSize()+1f));
        jLabel11.setText("Nodes per hidden layers:");

        txtLayersAndNodes.setFont(txtLayersAndNodes.getFont().deriveFont(txtLayersAndNodes.getFont().getSize()+2f));
        txtLayersAndNodes.setHorizontalAlignment(javax.swing.JTextField.CENTER);

        jLabel12.setFont(jLabel12.getFont().deriveFont((jLabel12.getFont().getStyle() | java.awt.Font.ITALIC)));
        jLabel12.setForeground(new java.awt.Color(51, 51, 51));
        jLabel12.setHorizontalAlignment(javax.swing.SwingConstants.CENTER);
        jLabel12.setText("Space seperated. Leave empty to determine automatically.");

        javax.swing.GroupLayout jPanel4Layout = new javax.swing.GroupLayout(jPanel4);
        jPanel4.setLayout(jPanel4Layout);
        jPanel4Layout.setHorizontalGroup(
            jPanel4Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(jPanel4Layout.createSequentialGroup()
                .addGap(5, 5, 5)
                .addGroup(jPanel4Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                    .addGroup(jPanel4Layout.createSequentialGroup()
                        .addComponent(jLabel11)
                        .addGap(10, 10, 10)
                        .addGroup(jPanel4Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                            .addComponent(jLabel12, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                            .addComponent(txtLayersAndNodes)))
                    .addGroup(jPanel4Layout.createSequentialGroup()
                        .addGroup(jPanel4Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                            .addComponent(jLabel9)
                            .addGroup(jPanel4Layout.createSequentialGroup()
                                .addComponent(jLabel13)
                                .addGap(18, 18, 18)
                                .addComponent(chkReplaceFiles)
                                .addGap(18, 18, 18)
                                .addComponent(chkIncludeAbsence)))
                        .addGap(0, 255, Short.MAX_VALUE)))
                .addContainerGap())
        );
        jPanel4Layout.setVerticalGroup(
            jPanel4Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(jPanel4Layout.createSequentialGroup()
                .addGap(5, 5, 5)
                .addComponent(jLabel9)
                .addGap(5, 5, 5)
                .addGroup(jPanel4Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.BASELINE)
                    .addComponent(chkReplaceFiles)
                    .addComponent(jLabel13)
                    .addComponent(chkIncludeAbsence))
                .addGap(5, 5, 5)
                .addGroup(jPanel4Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.BASELINE)
                    .addComponent(jLabel11)
                    .addComponent(txtLayersAndNodes, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE))
                .addGap(2, 2, 2)
                .addComponent(jLabel12)
                .addGap(5, 5, 5))
        );

        btnGenerateDatasets.setFont(btnGenerateDatasets.getFont().deriveFont(btnGenerateDatasets.getFont().getStyle() | java.awt.Font.BOLD, btnGenerateDatasets.getFont().getSize()+13));
        btnGenerateDatasets.setText("Generate Training and Testing Datasets");
        btnGenerateDatasets.setCursor(new java.awt.Cursor(java.awt.Cursor.HAND_CURSOR));
        btnGenerateDatasets.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                btnGenerateDatasetsActionPerformed(evt);
            }
        });

        btnTrainNeuralNetwork.setFont(btnTrainNeuralNetwork.getFont().deriveFont(btnTrainNeuralNetwork.getFont().getStyle() | java.awt.Font.BOLD, btnTrainNeuralNetwork.getFont().getSize()+13));
        btnTrainNeuralNetwork.setText("Create and Train Neural Network");
        btnTrainNeuralNetwork.setCursor(new java.awt.Cursor(java.awt.Cursor.HAND_CURSOR));
        btnTrainNeuralNetwork.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                btnTrainNeuralNetworkActionPerformed(evt);
            }
        });

        btnGenerateDistribution.setFont(btnGenerateDistribution.getFont().deriveFont(btnGenerateDistribution.getFont().getStyle() | java.awt.Font.BOLD, btnGenerateDistribution.getFont().getSize()+13));
        btnGenerateDistribution.setText("Generate Inferred Distribution");
        btnGenerateDistribution.setCursor(new java.awt.Cursor(java.awt.Cursor.HAND_CURSOR));
        btnGenerateDistribution.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                btnGenerateDistributionActionPerformed(evt);
            }
        });

        jLabel19.setFont(jLabel19.getFont().deriveFont(jLabel19.getFont().getStyle() | java.awt.Font.BOLD, jLabel19.getFont().getSize()+6));
        jLabel19.setText("Raster Datasets Folder");

        txtTrainingInputsFolderPath.setFont(txtTrainingInputsFolderPath.getFont().deriveFont(txtTrainingInputsFolderPath.getFont().getSize()+2f));
        txtTrainingInputsFolderPath.setHorizontalAlignment(javax.swing.JTextField.CENTER);
        txtTrainingInputsFolderPath.setText(trainingInputsFolder);
        txtTrainingInputsFolderPath.setEnabled(false);
        txtTrainingInputsFolderPath.setMinimumSize(new java.awt.Dimension(300, 22));
        txtTrainingInputsFolderPath.setPreferredSize(new java.awt.Dimension(400, 22));

        btnTrainingInputsBrowse.setFont(btnTrainingInputsBrowse.getFont().deriveFont(btnTrainingInputsBrowse.getFont().getSize()+2f));
        btnTrainingInputsBrowse.setText("Browse");
        btnTrainingInputsBrowse.setCursor(new java.awt.Cursor(java.awt.Cursor.HAND_CURSOR));
        btnTrainingInputsBrowse.addActionListener(new java.awt.event.ActionListener() {
            public void actionPerformed(java.awt.event.ActionEvent evt) {
                btnTrainingInputsBrowseActionPerformed(evt);
            }
        });

        javax.swing.GroupLayout jPanel8Layout = new javax.swing.GroupLayout(jPanel8);
        jPanel8.setLayout(jPanel8Layout);
        jPanel8Layout.setHorizontalGroup(
            jPanel8Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(jPanel8Layout.createSequentialGroup()
                .addGap(5, 5, 5)
                .addGroup(jPanel8Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                    .addGroup(jPanel8Layout.createSequentialGroup()
                        .addComponent(jLabel19)
                        .addGap(0, 0, Short.MAX_VALUE))
                    .addGroup(jPanel8Layout.createSequentialGroup()
                        .addComponent(txtTrainingInputsFolderPath, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                        .addGap(5, 5, 5)
                        .addComponent(btnTrainingInputsBrowse, javax.swing.GroupLayout.PREFERRED_SIZE, 107, javax.swing.GroupLayout.PREFERRED_SIZE)))
                .addGap(5, 5, 5))
        );
        jPanel8Layout.setVerticalGroup(
            jPanel8Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(jPanel8Layout.createSequentialGroup()
                .addGap(5, 5, 5)
                .addComponent(jLabel19)
                .addGap(5, 5, 5)
                .addGroup(jPanel8Layout.createParallelGroup(javax.swing.GroupLayout.Alignment.BASELINE)
                    .addComponent(txtTrainingInputsFolderPath, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                    .addComponent(btnTrainingInputsBrowse))
                .addGap(5, 5, 5))
        );

        javax.swing.GroupLayout layout = new javax.swing.GroupLayout(getContentPane());
        getContentPane().setLayout(layout);
        layout.setHorizontalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(layout.createSequentialGroup()
                .addContainerGap()
                .addGroup(layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
                    .addGroup(layout.createSequentialGroup()
                        .addGap(0, 0, Short.MAX_VALUE)
                        .addComponent(jLabel1)
                        .addGap(0, 0, Short.MAX_VALUE))
                    .addComponent(jPanel2, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                    .addComponent(jPanel4, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                    .addComponent(btnGenerateDistribution, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                    .addComponent(btnTrainNeuralNetwork, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                    .addComponent(jPanel8, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE)
                    .addComponent(btnGenerateDatasets, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE))
                .addContainerGap())
        );
        layout.setVerticalGroup(
            layout.createParallelGroup(javax.swing.GroupLayout.Alignment.LEADING)
            .addGroup(layout.createSequentialGroup()
                .addGap(10, 10, 10)
                .addComponent(jLabel1)
                .addGap(10, 10, 10)
                .addComponent(jPanel8, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addGap(10, 10, 10)
                .addComponent(jPanel2, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addGap(10, 10, 10)
                .addComponent(jPanel4, javax.swing.GroupLayout.PREFERRED_SIZE, javax.swing.GroupLayout.DEFAULT_SIZE, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addGap(20, 20, 20)
                .addComponent(btnGenerateDatasets, javax.swing.GroupLayout.PREFERRED_SIZE, 80, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addGap(20, 20, 20)
                .addComponent(btnTrainNeuralNetwork, javax.swing.GroupLayout.PREFERRED_SIZE, 80, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addGap(20, 20, 20)
                .addComponent(btnGenerateDistribution, javax.swing.GroupLayout.PREFERRED_SIZE, 80, javax.swing.GroupLayout.PREFERRED_SIZE)
                .addContainerGap(javax.swing.GroupLayout.DEFAULT_SIZE, Short.MAX_VALUE))
        );

        pack();
    }// </editor-fold>//GEN-END:initComponents

    private void btnDistributionsBrowseActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_btnDistributionsBrowseActionPerformed
        JFileChooser fileChooser = new JFileChooser(distributionsFolder);
        fileChooser.setMultiSelectionEnabled(false);
        fileChooser.setFileSelectionMode(JFileChooser.DIRECTORIES_ONLY);
        fileChooser.setDialogType(JFileChooser.OPEN_DIALOG);
        int result = fileChooser.showOpenDialog(this);
        if ((result != JFileChooser.ERROR_OPTION) && (result == JFileChooser.APPROVE_OPTION)) {
            distributionsFolder = fileChooser.getSelectedFile().toPath().toAbsolutePath().toString();
            txtDistributionsFolderPath.setText(distributionsFolder);
        }
    }//GEN-LAST:event_btnDistributionsBrowseActionPerformed

    private void btnGenerateDistributionActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_btnGenerateDistributionActionPerformed
        getGlassPane().setCursor(Cursor.getPredefinedCursor(Cursor.WAIT_CURSOR));
        getGlassPane().setVisible(true);
        try {
            // Get all the input files
            List<Path> lstTrainingFiles = new ArrayList<>();
            Files.walkFileTree(Paths.get(trainingInputsFolder), new SimpleFileVisitor<Path>() {
                @Override
                public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
                    if (file.getFileName().toString().toLowerCase().endsWith(".idi")) {
                        lstTrainingFiles.add(file);
                    }
                    return FileVisitResult.CONTINUE;
                }
            });
            // Load the values into memory
// TODO: A bit of a cumbersome data structure, but it works... Maybe use Double[][][] instead, but then I need to know the sizes before hand...
            List<List<List<Double>>> lstAllTrainingData = new ArrayList<>(lstTrainingFiles.size());
            for (Path file : lstTrainingFiles) {
                lstAllTrainingData.add(readDatasetFile(file));
            }
            // Get the neural networks
            List<Path> lstNeuralNetworkFiles = new ArrayList<>();
            Files.walkFileTree(Paths.get(distributionsFolder), new SimpleFileVisitor<Path>() {
                @Override
                public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
                    if (file.getFileName().toString().toLowerCase().endsWith(".nnet")) {
                        lstNeuralNetworkFiles.add(file);
                    }
                    return FileVisitResult.CONTINUE;
                }
            });
            for (Path file : lstNeuralNetworkFiles) {
                Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "Infer Distribution for: {0}", file.toString());
                // Load the neural network
                NeuralNetwork neuralNetwork = NeuralNetwork.createFromFile(file.toFile());
                // Calculate the infered distribution for each grid tile
                List<List<Double>> lstAllResults = new ArrayList<>();
                for (int row = 0; row < lstAllTrainingData.get(0).size(); row++) {
                    List<Double> lstResultRow = new ArrayList<>();
                    for (int col = 0; col < lstAllTrainingData.get(0).get(0).size(); col++) {
                        double[] inputs = new double[lstAllTrainingData.size()];
                        for (int inputDatasetIndex = 0; inputDatasetIndex < lstAllTrainingData.size(); inputDatasetIndex++) {
                            inputs[inputDatasetIndex] = lstAllTrainingData.get(inputDatasetIndex).get(row).get(col);
                        }
                        neuralNetwork.setInput(inputs);
                        neuralNetwork.calculate();
                        double[] outputs = neuralNetwork.getOutput();
                        lstResultRow.add(outputs[0]);
                    }
                    lstAllResults.add(lstResultRow);
                }
                // Write the calculated file
                String filename = file.getFileName().toString();
                Path inferredDistribution = file.getParent().resolve(filename.replace(".nnet", "_inferred_destribution.idi")).toAbsolutePath();
                Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "Writing File: {0}", inferredDistribution.toString());
                if (chkReplaceFiles.isSelected() || !Files.exists(file)) {
                    try (BufferedWriter writer = new BufferedWriter(new FileWriter(inferredDistribution.toFile()))) {
                        for (List<Double> lstResultRow : lstAllResults) {
                            for (double value : lstResultRow) {
                                writer.write(Double.toString(Math.round(value * 1000.0) / 1000.0));
                                writer.write(",");
                            }
                            writer.write(System.lineSeparator());
                        }
                        // Flushing and closing just to be paranoid (should be handled by the try-with-resources statement already)
                        writer.flush();
                        writer.close();
                    }
                    catch (IOException ex) {
                        Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.SEVERE, null, ex);
                    }
                }
                else {
                    Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "... The file will be skipped (not overwritten).");
                }
            }
            JOptionPane.showMessageDialog(this, "The Inferred Distribution have been calculated..", "FINISHED Calculate Inferred Distribution", 
                    JOptionPane.INFORMATION_MESSAGE);
        }
        catch (Exception ex) {
            Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.SEVERE, null, ex);
            JOptionPane.showMessageDialog(this, "The Inferred Distribution have NOT been calculated.", "ERROR Calculate Inferred Distribution", 
                    JOptionPane.ERROR_MESSAGE);
        }
        getGlassPane().setVisible(false);
        getGlassPane().setCursor(Cursor.getDefaultCursor());
    }//GEN-LAST:event_btnGenerateDistributionActionPerformed

    private void btnTrainNeuralNetworkActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_btnTrainNeuralNetworkActionPerformed
        getGlassPane().setCursor(Cursor.getPredefinedCursor(Cursor.WAIT_CURSOR));
        getGlassPane().setVisible(true);
        try {
            List<Path> lstTrainFiles = new ArrayList<>();
            Files.walkFileTree(Paths.get(distributionsFolder), new SimpleFileVisitor<Path>() {
                @Override
                public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
                    if (file.getFileName().toString().toLowerCase().endsWith("_train.tset")) {
                        lstTrainFiles.add(file);
                    }
                    return FileVisitResult.CONTINUE;
                }
            });
            for (Path file : lstTrainFiles) {
                Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "Begin training for: {0}", file.toString());
                // Load the trainng set
                DataSet trainingSet = DataSet.load(file.toAbsolutePath().toString());
                // Create the new neural network
                List<Integer> lstLayers = new ArrayList<>(3);
                if (!txtLayersAndNodes.getText().trim().isEmpty()) {
                    String[] providedLayers = txtLayersAndNodes.getText().trim().split(" ");
                    if (providedLayers.length > 0) {
                        lstLayers.add(trainingSet.getInputSize());
                        for (String hiddenLayer : providedLayers) {
                            lstLayers.add(Integer.parseInt(hiddenLayer));
                        }
                        lstLayers.add(trainingSet.getOutputSize());
                    }
                }
                if (lstLayers.isEmpty()) {
                    lstLayers.add(trainingSet.getInputSize());
                    lstLayers.add((int) (trainingSet.getInputSize() * 0.85));
                    lstLayers.add((int) (trainingSet.getInputSize() * 0.65));
                    lstLayers.add((int) (trainingSet.getInputSize() * 0.35));
                    lstLayers.add((int) (trainingSet.getInputSize() * 0.2));
                    lstLayers.add(trainingSet.getOutputSize());
                }
                MultiLayerPerceptron neuralNetwork = new MultiLayerPerceptron(lstLayers);
                // Train the neural network
                BackPropagation learningRules = new BackPropagation();
                learningRules.setMaxError(0.01);
                learningRules.setLearningRate(0.2);
                neuralNetwork.learn(trainingSet, learningRules);
// TODO: Which of these are useful to show to the user (if any)?
Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "PreviousEpochError: {0}", learningRules.getPreviousEpochError());
Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "TotalNetworkError: {0}", learningRules.getTotalNetworkError());
                // Save the trained neural network
                String filename = file.getFileName().toString();
                if (chkReplaceFiles.isSelected() || !Files.exists(file)) {
                    neuralNetwork.save(file.getParent().resolve(filename.replace("_train.tset", ".nnet")).toAbsolutePath().toString());
                }
                else {
                    Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "... The file will be skipped (not overwritten).");
                }
                Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "Finished training for: {0}", file.toString());
            }
            JOptionPane.showMessageDialog(this, "The Neural Network training has completed.", "FINISHED Training", 
                    JOptionPane.INFORMATION_MESSAGE);
        }
        catch (Exception ex) {
            Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.SEVERE, null, ex);
            JOptionPane.showMessageDialog(this, "The Neural Network training has NOT completed.", "ERROR Training", 
                    JOptionPane.ERROR_MESSAGE);
        }
        getGlassPane().setVisible(false);
        getGlassPane().setCursor(Cursor.getDefaultCursor());
    }//GEN-LAST:event_btnTrainNeuralNetworkActionPerformed

    private void btnTrainingInputsBrowseActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_btnTrainingInputsBrowseActionPerformed
        JFileChooser fileChooser = new JFileChooser(trainingInputsFolder);
        fileChooser.setMultiSelectionEnabled(false);
        fileChooser.setFileSelectionMode(JFileChooser.DIRECTORIES_ONLY);
        fileChooser.setDialogType(JFileChooser.OPEN_DIALOG);
        int result = fileChooser.showOpenDialog(this);
        if ((result != JFileChooser.ERROR_OPTION) && (result == JFileChooser.APPROVE_OPTION)) {
            trainingInputsFolder = fileChooser.getSelectedFile().toPath().toAbsolutePath().toString();
            txtTrainingInputsFolderPath.setText(trainingInputsFolder);
        }
    }//GEN-LAST:event_btnTrainingInputsBrowseActionPerformed

    private void btnGenerateDatasetsActionPerformed(java.awt.event.ActionEvent evt) {//GEN-FIRST:event_btnGenerateDatasetsActionPerformed
        getGlassPane().setCursor(Cursor.getPredefinedCursor(Cursor.WAIT_CURSOR));
        getGlassPane().setVisible(true);
        try {
            // Get all the input files
            List<Path> lstTrainingFiles = new ArrayList<>();
            Files.walkFileTree(Paths.get(trainingInputsFolder), new SimpleFileVisitor<Path>() {
                @Override
                public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
                    if (file.getFileName().toString().toLowerCase().endsWith(".idi")) {
                        lstTrainingFiles.add(file);
                    }
                    return FileVisitResult.CONTINUE;
                }
            });
            // Load the values into memory
// TODO: A bit of a cumbersome data structure, but it works... Maybe use Double[][][] instead, but then I need to know the sizes before hand...
            List<List<List<Double>>> lstAllTrainingData = new ArrayList<>(lstTrainingFiles.size());
            for (Path file : lstTrainingFiles) {
                lstAllTrainingData.add(readDatasetFile(file));
            }
            // Get all the distributions to be calculated
            List<Path> lstAbsenceFiles = new ArrayList<>();
            List<Path> lstPresenceFiles = new ArrayList<>();
            Files.walkFileTree(Paths.get(distributionsFolder), new SimpleFileVisitor<Path>() {
                @Override
                public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException {
                    if (file.getFileName().toString().toLowerCase().endsWith("_absence.idi")) {
                        lstAbsenceFiles.add(file);
                    }
                    else
                    if (file.getFileName().toString().toLowerCase().endsWith("_presence.idi")) {
                        lstPresenceFiles.add(file);
                    }
                    return FileVisitResult.CONTINUE;
                }
            });
            // Create the training dataset and the full distribution testing dataset
            int numberOfInputs = lstTrainingFiles.size();
            for (int fileIndex = 0; fileIndex < lstPresenceFiles.size(); fileIndex++) {
                Path file = lstPresenceFiles.get(fileIndex);
                String filename = file.getFileName().toString();
                DataSet trainingSet = new DataSet(numberOfInputs, 1);
                DataSet testingSet = new DataSet(numberOfInputs, 1);
                // Populate the datasets
                List<List<Double>> lstAbsenceData = readDatasetFile(lstAbsenceFiles.get(fileIndex));
                List<List<Double>> lstPresenceData = readDatasetFile(file);
                for (int row = 0; row < lstPresenceData.size(); row++) {
                    List<Double> lstAbsenceValues = lstAbsenceData.get(row);
                    List<Double> lstPresenceValues = lstPresenceData.get(row);
                    for (int col = 0; col < lstPresenceValues.size(); col++) {
                        double absence = lstAbsenceValues.get(col);
                        double presence = lstPresenceValues.get(col);
                        double value = Double.MIN_VALUE;
                        // Select values that are good enough to train with
                        if (chkIncludeAbsence.isSelected() && absence > 0.5) {
                            value = 0.0;
                        }
                        else
                        if (presence > 0.25) {
                            value = presence;
                        }
                        if (value >= 0.0) {
                            ArrayList<Double> inputs = new ArrayList<>(lstAllTrainingData.size());
                            for (List<List<Double>> lstInputDataset : lstAllTrainingData) {
                                inputs.add(lstInputDataset.get(row).get(col));
                            }
                            ArrayList<Double> outputs = new ArrayList<>(1);
                            outputs.add(value);
                            trainingSet.addRow(new DataSetRow(inputs, outputs));
                        }
                        // Select values that are good enough to test with
                        if (chkIncludeAbsence.isSelected() && absence > 0.15) {
                            value = 0.0;
                        }
                        else
                        if (presence > 0.0) {
                            value = presence;
                        }
                        if (value >= 0.0) {
                            ArrayList<Double> inputs = new ArrayList<>(lstAllTrainingData.size());
                            for (List<List<Double>> lstInputDataset : lstAllTrainingData) {
                                inputs.add(lstInputDataset.get(row).get(col));
                            }
                            ArrayList<Double> outputs = new ArrayList<>(1);
                            outputs.add(value);
                            testingSet.addRow(new DataSetRow(inputs, outputs));
                        }
                    }
                }
                // Save the dataset files
                Path trainingFile = file.getParent().resolve(filename.replace(".idi", "_train.tset")).toAbsolutePath();
                if (chkReplaceFiles.isSelected() || !Files.exists(trainingFile)) {
                    trainingSet.save(trainingFile.toString());
                    Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "Saving training dataset: {0}", trainingFile.toString());
                }
                else {
                    Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "... The file will be skipped (not overwritten).");
                }
                Path testingFile = file.getParent().resolve(filename.replace(".idi", "_test.tset")).toAbsolutePath();
                if (chkReplaceFiles.isSelected() || !Files.exists(testingFile)) {
                    testingSet.save(testingFile.toString());
                    Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "Saving testing dataset: {0}", testingFile.toString());
                }
                else {
                    Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.INFO, "... The file will be skipped (not overwritten).");
                }
            }
            JOptionPane.showMessageDialog(this, "The training and testing datasets have been generated.", "FINISHED Generating Datasets", 
                    JOptionPane.INFORMATION_MESSAGE);
        }
        catch (Exception ex) {
            Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.SEVERE, null, ex);
            JOptionPane.showMessageDialog(this, "The training and testing datasets have NOT been generated.", "ERROR Generating Datasets", 
                    JOptionPane.ERROR_MESSAGE);
        }
        getGlassPane().setVisible(false);
        getGlassPane().setCursor(Cursor.getDefaultCursor());
    }//GEN-LAST:event_btnGenerateDatasetsActionPerformed

    private List<List<Double>> readDatasetFile(Path file) throws NumberFormatException {
        List<List<Double>> lstAllRowValues = new ArrayList<>();
        try (BufferedReader reader = new BufferedReader(new FileReader(file.toFile()))) {
            final String SEPARATOR_CHAR = ",";
            String line = null;
            while ((line = reader.readLine()) != null) {
                if (!line.trim().isEmpty()) {
                    String[] dataRow = line.split(SEPARATOR_CHAR);
                    List<Double> lstSingleRow = new ArrayList<>(dataRow.length);
                    for (String data : dataRow) {
                        lstSingleRow.add(Double.parseDouble(data));
                    }
                    lstAllRowValues.add(lstSingleRow);
                }
            }
            // Closing just to be paranoid (should be handled by the try-with-resources statement already)
            reader.close();
        }
        catch (IOException ex) {
            Logger.getLogger(NeuralNetworkProcessorApp.class.getName()).log(Level.SEVERE, null, ex);
        }
        return lstAllRowValues;
    }
    
    // Variables declaration - do not modify//GEN-BEGIN:variables
    private javax.swing.JButton btnDistributionsBrowse;
    private javax.swing.JButton btnGenerateDatasets;
    private javax.swing.JButton btnGenerateDistribution;
    private javax.swing.JButton btnTrainNeuralNetwork;
    private javax.swing.JButton btnTrainingInputsBrowse;
    private javax.swing.JCheckBox chkIncludeAbsence;
    private javax.swing.JCheckBox chkReplaceFiles;
    private javax.swing.JLabel jLabel1;
    private javax.swing.JLabel jLabel11;
    private javax.swing.JLabel jLabel12;
    private javax.swing.JLabel jLabel13;
    private javax.swing.JLabel jLabel19;
    private javax.swing.JLabel jLabel7;
    private javax.swing.JLabel jLabel9;
    private javax.swing.JPanel jPanel2;
    private javax.swing.JPanel jPanel4;
    private javax.swing.JPanel jPanel8;
    private javax.swing.JTextField txtDistributionsFolderPath;
    private javax.swing.JTextField txtLayersAndNodes;
    private javax.swing.JTextField txtTrainingInputsFolderPath;
    // End of variables declaration//GEN-END:variables
}
